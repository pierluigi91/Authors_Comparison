def tokenize(text):
    return text.lower().split(' ')



#
# def tokenize(text):
#     res=''
#     for line in text:
#         for word in line.split(' '):
#             res += word
#     return res